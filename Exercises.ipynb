{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO5tWpp05cBsmctxL6kzkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianerr/CSST-101/blob/main/Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Propositional Logic in Python"
      ],
      "metadata": {
        "id": "Me_MrjQL5MOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OP7_f4Exxb7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2165b081-97fa-417d-bda1-a472642d3e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The match will not light\n"
          ]
        }
      ],
      "source": [
        "rains = True\n",
        "\n",
        "def ground_wet(rains):\n",
        "  return rains\n",
        "\n",
        "def match_lights(ground_wet):\n",
        "  return not ground_wet\n",
        "\n",
        "if rains:\n",
        "  is_ground_wet = ground_wet(rains)\n",
        "  can_match_light = match_lights(is_ground_wet)\n",
        "\n",
        "  if can_match_light:\n",
        "    print(\"Thy will light\")\n",
        "  else:\n",
        "    print(\"The match will not light\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Predicate Logic Representation"
      ],
      "metadata": {
        "id": "SXt17sQP8_kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isHuman(person):\n",
        "  return person == \"Socrates\"\n",
        "\n",
        "def isMortal(person):\n",
        "  if isHuman(person):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "person = \"Socrates\"\n",
        "if isMortal(person):\n",
        "  print(f\"{person} is mortal\")\n",
        "else:\n",
        "  print(f\"{person} is not mortal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EWy8zWa9Iqr",
        "outputId": "9d27310c-376d-4c8d-f45e-9eae599b14ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Socrates is mortal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Inference Techniques Logic-Based Systems"
      ],
      "metadata": {
        "id": "9k0beTDK_OO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moodus_ponens(rules, facts):\n",
        "  conclusions = []\n",
        "  for rule in rules:\n",
        "    premise, conclusion = rule\n",
        "    if premise in facts:\n",
        "      conclusions. append(conclusion)\n",
        "  return conclusions\n",
        "\n",
        "rules = [{\"X\", \"Y\"}]\n",
        "\n",
        "facts = {\"X\"}\n",
        "\n",
        "conclusions = moodus_ponens(rules,facts)\n",
        "print(\"Inferred Conclusions: \", conclusions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVAtLAr2_WOe",
        "outputId": "f31b0449-dc35-44f9-e335-b62d515da583"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred Conclusions:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4"
      ],
      "metadata": {
        "id": "ru83_S4pAv0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hungry = True\n",
        "eats = False\n",
        "\n",
        "if hungry:\n",
        "  eats = True\n",
        "\n",
        "if eats:\n",
        "  hungry = False\n",
        "\n",
        "if not hungry:\n",
        "  print(\"John is no longer hungry\")\n",
        "else:\n",
        "  print(\"John is still hungry\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mswe6VNA1SO",
        "outputId": "193045f0-502c-4577-b5bd-9f5e5c0fbd60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John is no longer hungry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5"
      ],
      "metadata": {
        "id": "Cy61kTh_B51Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_greeting(statement):\n",
        "  greetings = [\"hello\", \"hi\", \"hey\"]\n",
        "  return statement.lower() in greetings\n",
        "\n",
        "def respond(statement):\n",
        "  if is_greeting(statement):\n",
        "    return \"Hello! How can I assist you today?\"\n",
        "  else:\n",
        "    return \"I'm sorry, I didn't quite catch that\"\n",
        "\n",
        "user_input = input(\"User: \")\n",
        "response = respond(user_input)\n",
        "print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQvH5NRfB724",
        "outputId": "ce0ff303-b021-4773-b944-b31e72ebcf69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: user\n",
            "Chatbot: I'm sorry, I didn't quite catch that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study Discussion"
      ],
      "metadata": {
        "id": "N3DrUMvsE2df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "report = \"\"\"Medical diagnosis expert systems are a prime example of logic-based\n",
        "AI in action. They use proportional and predicate logic to represent medical\n",
        "knowledge and infer diagnoses from patient symptoms, kind of like a super smart\n",
        "doctor following a detailed flowchart. This makes their decisions transparent\n",
        "and consistent, which is a big plus. However, building and maintaining these\n",
        "systems is a challenge due to the complexityof medical knowledge and the need\n",
        "to handle uncertainty.\"\"\"\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "vFyGIeHtE48b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b926f8c3-c5ea-48b5-8445-cd210690b42d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medical diagnosis expert systems are a prime example of logic-based\n",
            "AI in action. They use proportional and predicate logic to represent medical\n",
            "knowledge and infer diagnoses from patient symptoms, kind of like a super smart\n",
            "doctor following a detailed flowchart. This makes their decisions transparent \n",
            "and consistent, which is a big plus. However, building and maintaining these \n",
            "systems is a challenge due to the complexityof medical knowledge and the need \n",
            "to handle uncertainty.\n"
          ]
        }
      ]
    }
  ]
}